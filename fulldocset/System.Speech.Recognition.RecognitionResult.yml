### YamlMime:ManagedReference
items:
- uid: System.Speech.Recognition.RecognitionResult
  id: RecognitionResult
  children:
  - System.Speech.Recognition.RecognitionResult.Alternates
  - System.Speech.Recognition.RecognitionResult.Audio
  - System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  - System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  langs:
  - csharp
  name: RecognitionResult
  nameWithType: RecognitionResult
  fullName: System.Speech.Recognition.RecognitionResult
  type: Class
  summary: "Zawiera szczegółowe informacje o danych wejściowych, który został rozpoznany przez wystąpienia <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> lub <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref>."
  remarks: "Ta klasa pochodzi od <xref:System.Speech.Recognition.RecognizedPhrase>i zawiera szczegółowe informacje na temat rozpoznawania mowy, w tym następujące: - <xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A>odwołań do właściwości <xref:System.Speech.Recognition.Grammar>czy aparat rozpoznawania używany do identyfikowania mowy.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.RecognizedPhrase.Grammar%2A> </xref:System.Speech.Recognition.RecognizedPhrase>      - <xref:System.Speech.Recognition.RecognizedPhrase.Text%2A>Właściwość zawiera znormalizowane tekst frazy.</xref:System.Speech.Recognition.RecognizedPhrase.Text%2A> Aby uzyskać więcej informacji na temat normalizacji tekstu zobacz <xref:System.Speech.Recognition.ReplacementText>.</xref:System.Speech.Recognition.ReplacementText>      - <xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A>Semantycznego informacje zawarte w wyniku odwołuje się do właściwości.</xref:System.Speech.Recognition.RecognizedPhrase.Semantics%2A> Informacje semantyczne jest słownikiem nazwy kluczy i skojarzone dane semantycznego.      - <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>Właściwość zawiera zbiór <xref:System.Speech.Recognition.RecognizedPhrase>obiektów, które reprezentują inne interpretacji candidate wejście audio.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult.Alternates%2A> Zobacz <xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>Aby uzyskać dodatkowe informacje.</xref:System.Speech.Recognition.RecognitionResult.Alternates%2A>      - <xref:System.Speech.Recognition.RecognizedPhrase.Words%2A>Właściwość zawiera uporządkowaną kolekcję <xref:System.Speech.Recognition.RecognizedWordUnit>obiekty reprezentujące każdego rozpoznany programu word w danych wejściowych.</xref:System.Speech.Recognition.RecognizedWordUnit> </xref:System.Speech.Recognition.RecognizedPhrase.Words%2A> Każdy <xref:System.Speech.Recognition.RecognizedWordUnit>zawiera informacje wymowy dla odpowiedniego programu word, format leksykalne i format wyświetlania.</xref:System.Speech.Recognition.RecognizedWordUnit>       Niektóre elementy członkowskie z <xref:System.Speech.Recognition.SpeechRecognitionEngine>, <xref:System.Speech.Recognition.SpeechRecognizer>, i <xref:System.Speech.Recognition.Grammar>klasy może powodować generowanie RecognitionResult.</xref:System.Speech.Recognition.Grammar> </xref:System.Speech.Recognition.SpeechRecognizer> </xref:System.Speech.Recognition.SpeechRecognitionEngine> Aby uzyskać więcej informacji zobacz następujące metod i zdarzeń.      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognitionEngine> class:          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized>      -   Methods and events of the <xref:System.Speech.Recognition.SpeechRecognizer> class:          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected>          -   <xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized>      -   The <xref:System.Speech.Recognition.Grammar.SpeechRecognized> event of the <xref:System.Speech.Recognition.Grammar> class.</xref:System.Speech.Recognition.Grammar></xref:System.Speech.Recognition.Grammar.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognizer.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognizer.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognizer.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognizer></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognized></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechRecognitionRejected></xref:System.Speech.Recognition.SpeechRecognitionEngine.SpeechHypothesized></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognizeAsync%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine.EmulateRecognize%2A></xref:System.Speech.Recognition.SpeechRecognitionEngine>       Aby uzyskać więcej informacji o zdarzeniach rozpoznawania, zobacz [przy użyciu zdarzenia rozpoznawania mowy](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."
  example:
  - "The following example shows a handler for the `SpeechRecognized` event of a <xref:System.Speech.Recognition.SpeechRecognitionEngine> or <xref:System.Speech.Recognition.SpeechRecognizer> object, and some of the information about the associated RecognitionResult.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: >-
      [System.Diagnostics.DebuggerDisplay("{DebuggerDisplayString ()}")]

      public sealed class RecognitionResult : System.Speech.Recognition.RecognizedPhrase, System.Runtime.Serialization.ISerializable
  inheritance:
  - System.Object
  - System.Speech.Recognition.RecognizedPhrase
  implements:
  - System.Runtime.Serialization.ISerializable
  inheritedMembers:
  - System.Speech.Recognition.RecognizedPhrase.Confidence
  - System.Speech.Recognition.RecognizedPhrase.ConstructSmlFromSemantics
  - System.Speech.Recognition.RecognizedPhrase.Grammar
  - System.Speech.Recognition.RecognizedPhrase.HomophoneGroupId
  - System.Speech.Recognition.RecognizedPhrase.Homophones
  - System.Speech.Recognition.RecognizedPhrase.ReplacementWordUnits
  - System.Speech.Recognition.RecognizedPhrase.Semantics
  - System.Speech.Recognition.RecognizedPhrase.Text
  - System.Speech.Recognition.RecognizedPhrase.Words
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  id: Alternates
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Pobiera kolekcję możliwych dopasowań dla danych wejściowych do rozpoznawania mowy."
  remarks: "Rozpoznawanie zastępców są uporządkowane według wartości ich <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>Właściwości.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Wartość zaufania danego frazy wskazuje prawdopodobieństwo frazę zgodność danych wejściowych. Wyrażenie o najwyższej wartości zaufania jest frazę, które najprawdopodobniej odpowiada danych wejściowych.       Każdy <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>wartość należy ocenić indywidualnie i bez odwołania do wartości zaufania innych alternatyw.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A> Właściwości który <xref:System.Speech.Recognition.RecognitionResult>dziedziczy <xref:System.Speech.Recognition.RecognizedPhrase>zawierają szczegółowe informacje o zwrot z najwyższym wynik zaufania.</xref:System.Speech.Recognition.RecognizedPhrase> </xref:System.Speech.Recognition.RecognitionResult>       Jedno użycie dla kolekcji zastępców dotyczy korekcja błędów automatycznych. Na przykład podczas projektowania katalogu okna dialogowego, aplikacja może Monituj użytkownika o Sprawdź, czy aplikacja ma poprawne informacje ze zdarzenia rozpoznawania, podobnie jak w &quot;wyjaśnić, co znaczy&quot;Anna&quot;?&quot; Jeśli użytkownik odpowie &quot;nie&quot;, a następnie aplikacja może wykonać kwerendy dla użytkownika o zastępców, które miały wystarczająco duży <xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>wynik.</xref:System.Speech.Recognition.RecognizedPhrase.Confidence%2A>       Aby uzyskać więcej informacji na temat rozpoznawania mowy i użyj alternatyw rozpoznawania, zobacz [rozpoznawania mowy](http://msdn.microsoft.com/en-us/6a7dc524-07fc-4862-8d48-8c10dc64b919) i [przy użyciu zdarzenia rozpoznawania mowy](http://msdn.microsoft.com/en-us/01c598ca-2e0e-4e89-b303-cd1cef9e8482)."
  example:
  - "The following example shows a handler for the `SpeechRecognized` event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n  Console.WriteLine(\"Grammar({0}), {1}: {2}\",  \n    e.Result.Grammar.Name, e.Result.Audio.Duration, e.Result.Text);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase> Alternates { get; }
    return:
      type: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
      description: "Kolekcja tylko do odczytu alternatyw rozpoznawania."
  overload: System.Speech.Recognition.RecognitionResult.Alternates*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.Audio
  id: Audio
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
  type: Property
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Pobiera audio skojarzony z wynikiem rozpoznawania."
  remarks: "Aby uzyskać części audio, który jest skojarzony z określonego zakresu słów w wyniku rozpoznawania, należy użyć <xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>metody.</xref:System.Speech.Recognition.RecognitionResult.GetAudioForWordRange%2A>"
  example:
  - "The following example shows a handler for the **SpeechRecognized** event and some of the information about the associated <xref:System.Speech.Recognition.RecognitionResult>.  \n  \n```c#  \n  \n// Handle the SpeechRecognized event.   \nvoid SpeechRecognizedHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  // Add event handler code here.  \n  \n  // The following code illustrates some of the information available  \n  // in the recognition result.  \n      Console.WriteLine(\"Grammar({0}): {1}\", e.Result.Grammar.Name, e.Result.Text);  \n      Console.WriteLine(\"Audio for result:\");  \n      Console.WriteLine(\"  Start time: \"+ e.Result.Audio.StartTime);  \n      Console.WriteLine(\"  Duration: \" + e.Result.Audio.Duration);  \n      Console.WriteLine(\"  Format: \" + e.Result.Audio.Format.EncodingFormat);  \n  \n  // Display the semantic values in the recognition result.  \n  foreach (KeyValuePair<String, SemanticValue> child in e.Result.Semantics)  \n  {  \n    Console.WriteLine(\" {0} key: {1}\",  \n      child.Key, child.Value.Value ?? \"null\");  \n  }  \n  Console.WriteLine();  \n  \n  // Display information about the words in the recognition result.  \n  foreach (RecognizedWordUnit word in e.Result.Words)  \n  {  \n    RecognizedAudio audio = e.Result.GetAudioForWordRange(word, word);  \n    Console.WriteLine(\" {0,-10} {1,-10} {2,-10} {3} ({4})\",  \n      word.Text, word.LexicalForm, word.Pronunciation,  \n      audio.Duration, word.DisplayAttributes);  \n  }  \n  \n  // Display the recognition alternates for the result.  \n  foreach (RecognizedPhrase phrase in e.Result.Alternates)  \n  {  \n    Console.WriteLine(\" alt({0}) {1}\", phrase.Confidence, phrase.Text);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio Audio { get; }
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "Dźwięk skojarzony z wynikiem rozpoznawania lub <xref uid=&quot;langword_csharp_null&quot; name=&quot;null&quot; href=&quot;&quot;> </xref> Jeśli aparat rozpoznawania wygenerowanych wynik po wywołaniu <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref> lub <xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;> </xref> metody <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> lub <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> wystąpienia."
  overload: System.Speech.Recognition.RecognitionResult.Audio*
  exceptions: []
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  id: GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Pobiera część audio, który jest skojarzony z określonego zakresu słów w wyniku rozpoznawania."
  remarks: "Aby uzyskać pełną nagrań audio, związanych z wynikiem rozpoznawania, należy użyć <xref:System.Speech.Recognition.RecognitionResult.Audio%2A>Właściwości.</xref:System.Speech.Recognition.RecognitionResult.Audio%2A>"
  example:
  - "The following example creates a grammar to accept name input and attaches to it a handler for the `SpeechRecognized` event. The grammar uses a wildcard for the name element of the phrase. The event handler uses the audio from the wildcard to create and play a greeting prompt.  \n  \n```c#  \n  \nprivate Grammar CreateNameInputGrammar()  \n{  \n  GrammarBuilder wildcardBuilder = new GrammarBuilder();  \n  wildcardBuilder.AppendWildcard();  \n  SemanticResultKey nameKey =  \n    new SemanticResultKey(\"Name\", wildcardBuilder);  \n  \n  GrammarBuilder nameBuilder =  \n    new GrammarBuilder(\"My name is\");  \n  nameBuilder.Append(nameKey);  \n  \n  Grammar nameGrammar = new Grammar(nameBuilder);  \n  nameGrammar.Name = \"Name input\";  \n  \n  nameGrammar.SpeechRecognized +=  \n    new EventHandler<SpeechRecognizedEventArgs>(  \n      NameInputHandler);  \n  \n  return nameGrammar;  \n}  \n  \n// Handle the SpeechRecognized event for the name grammar.  \nprivate void NameInputHandler(object sender, SpeechRecognizedEventArgs e)  \n{  \n  if (e.Result == null) return;  \n  \n  RecognitionResult result = e.Result;  \n  SemanticValue semantics = e.Result.Semantics;  \n  \n  if (semantics.ContainsKey(\"Name\"))  \n  {  \n    RecognizedAudio nameAudio =  \n      result.GetAudioForWordRange(  \n        result.Words[3], result.Words[result.Words.Count - 1]);  \n  \n    // Save the audio. Create a directory and file as necessary.  \n    FileInfo fi = new FileInfo(@\"C:\\temp\\temp.wav\");  \n    if (!fi.Directory.Exists)  \n    {  \n      fi.Directory.Create();  \n    }  \n    FileStream stream = new FileStream(fi.FullName, FileMode.Create);  \n    nameAudio.WriteToWaveStream(stream);  \n    stream.Close();  \n  \n    // Greet the person using the saved audio.  \n    SpeechSynthesizer synthesizer = new SpeechSynthesizer();  \n    PromptBuilder builder = new PromptBuilder();  \n    builder.AppendText(\"Hello\");  \n    builder.AppendAudio(fi.FullName);  \n    synthesizer.Speak(builder);  \n  }  \n}  \n```"
  syntax:
    content: public System.Speech.Recognition.RecognizedAudio GetAudioForWordRange (System.Speech.Recognition.RecognizedWordUnit firstWord, System.Speech.Recognition.RecognizedWordUnit lastWord);
    parameters:
    - id: firstWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "Pierwsze słowo w zakresie."
    - id: lastWord
      type: System.Speech.Recognition.RecognizedWordUnit
      description: "Wyraz ostatniej w zakresie."
    return:
      type: System.Speech.Recognition.RecognizedAudio
      description: "Sekcja nagrań audio, związanych z zakresem programu word."
  overload: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  exceptions:
  - type: System.NullReferenceException
    commentId: T:System.NullReferenceException
    description: "Aparat rozpoznawania wygenerowanych wynik po wywołaniu <xref uid=&quot;langword_csharp_EmulateRecognize&quot; name=&quot;EmulateRecognize&quot; href=&quot;&quot;> </xref> lub <xref uid=&quot;langword_csharp_EmulateRecognizeAsync&quot; name=&quot;EmulateRecognizeAsync&quot; href=&quot;&quot;> </xref> metody <xref href=&quot;System.Speech.Recognition.SpeechRecognizer&quot;> </xref> lub <xref href=&quot;System.Speech.Recognition.SpeechRecognitionEngine&quot;> </xref> obiektów."
  platform:
  - net462
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  id: System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  isEii: true
  parent: System.Speech.Recognition.RecognitionResult
  langs:
  - csharp
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  type: Method
  assemblies:
  - System.Speech
  namespace: System.Speech.Recognition
  summary: "Wypełnia <xref href=&quot;System.Runtime.Serialization.SerializationInfo&quot;> </xref> wystąpienia o dane potrzebne do zserializowania obiektu docelowego."
  remarks: "Ten element jest jawną implementacją elementu interfejsu. Można go używać tylko wtedy, gdy <xref:System.Speech.Recognition.RecognitionResult>wystąpienia jest rzutowane na <xref:System.Runtime.Serialization.ISerializable>interfejsu.</xref:System.Runtime.Serialization.ISerializable> </xref:System.Speech.Recognition.RecognitionResult>"
  syntax:
    content: void ISerializable.GetObjectData (System.Runtime.Serialization.SerializationInfo info, System.Runtime.Serialization.StreamingContext context);
    parameters:
    - id: info
      type: System.Runtime.Serialization.SerializationInfo
      description: "Obiekt do wypełniania danych."
    - id: context
      type: System.Runtime.Serialization.StreamingContext
      description: "Lokalizacja docelowa dla serializacji."
  overload: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  exceptions: []
  platform:
  - net462
references:
- uid: System.Speech.Recognition.RecognizedPhrase
  isExternal: false
  name: System.Speech.Recognition.RecognizedPhrase
- uid: System.NullReferenceException
  isExternal: true
  name: System.NullReferenceException
- uid: System.Speech.Recognition.RecognitionResult.Alternates
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
  fullName: System.Speech.Recognition.RecognitionResult.Alternates
- uid: System.Collections.ObjectModel.ReadOnlyCollection{System.Speech.Recognition.RecognizedPhrase}
  parent: System.Collections.ObjectModel
  isExternal: true
  name: ReadOnlyCollection<RecognizedPhrase>
  nameWithType: ReadOnlyCollection<RecognizedPhrase>
  fullName: System.Collections.ObjectModel.ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  spec.csharp:
  - uid: System.Collections.ObjectModel.ReadOnlyCollection`1
    name: ReadOnlyCollection
    nameWithType: ReadOnlyCollection
    fullName: ReadOnlyCollection<System.Speech.Recognition.RecognizedPhrase>
  - name: <
    nameWithType: <
    fullName: <
  - uid: System.Speech.Recognition.RecognizedPhrase
    name: RecognizedPhrase
    nameWithType: RecognizedPhrase
    fullName: RecognizedPhrase
  - name: '>'
    nameWithType: '>'
    fullName: '>'
- uid: System.Speech.Recognition.RecognitionResult.Audio
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
  fullName: System.Speech.Recognition.RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognizedAudio
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedAudio
  nameWithType: RecognizedAudio
  fullName: System.Speech.Recognition.RecognizedAudio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(System.Speech.Recognition.RecognizedWordUnit,System.Speech.Recognition.RecognizedWordUnit)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  nameWithType: RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
  fullName: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange(RecognizedWordUnit,RecognizedWordUnit)
- uid: System.Speech.Recognition.RecognizedWordUnit
  parent: System.Speech.Recognition
  isExternal: false
  name: RecognizedWordUnit
  nameWithType: RecognizedWordUnit
  fullName: System.Speech.Recognition.RecognizedWordUnit
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData(System.Runtime.Serialization.SerializationInfo,System.Runtime.Serialization.StreamingContext)
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
  fullName: System.Speech.Recognition.RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData(SerializationInfo,StreamingContext)
- uid: System.Runtime.Serialization.SerializationInfo
  parent: System.Runtime.Serialization
  isExternal: false
  name: SerializationInfo
  nameWithType: SerializationInfo
  fullName: System.Runtime.Serialization.SerializationInfo
- uid: System.Runtime.Serialization.StreamingContext
  parent: System.Runtime.Serialization
  isExternal: true
  name: StreamingContext
  nameWithType: StreamingContext
  fullName: System.Runtime.Serialization.StreamingContext
- uid: System.Speech.Recognition.RecognitionResult.Alternates*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Alternates
  nameWithType: RecognitionResult.Alternates
- uid: System.Speech.Recognition.RecognitionResult.Audio*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: Audio
  nameWithType: RecognitionResult.Audio
- uid: System.Speech.Recognition.RecognitionResult.GetAudioForWordRange*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: GetAudioForWordRange
  nameWithType: RecognitionResult.GetAudioForWordRange
- uid: System.Speech.Recognition.RecognitionResult.System#Runtime#Serialization#ISerializable#GetObjectData*
  parent: System.Speech.Recognition.RecognitionResult
  isExternal: false
  name: System.Runtime.Serialization.ISerializable.GetObjectData
  nameWithType: RecognitionResult.System.Runtime.Serialization.ISerializable.GetObjectData
